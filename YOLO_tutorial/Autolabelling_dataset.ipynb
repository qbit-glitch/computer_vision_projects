{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f96sJ0tCWyoo"
      },
      "source": [
        "### Steps in this tutorial\n",
        "\n",
        "We are going to cover :\n",
        "- Setup\n",
        "- Image Dataset preparation\n",
        "- Autolabel dataset\n",
        "- Train target model\n",
        "- Evaluate target model\n",
        "- Run video inference\n",
        "- Upload dataset and model to Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgdrFMqZWyWF",
        "outputId": "4d81e234-0474-4216-cdef-3514f394ac83"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHnW-O82X2M9"
      },
      "source": [
        "### Install autodistill\n",
        "   Autodistill is an ecosystem for using slower foundation model to train small faster supervised models. Each Base as well as the target model has its own separate repository and pip package.\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7j7u9qcWSCr"
      },
      "outputs": [],
      "source": [
        "!pip install -q autodistill autodistill-grounded-sam autodistill-yolov8 supervision==0.9.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F9otEzkY6x-"
      },
      "source": [
        "NOTE: to make it easier for us to manage datasets, images and models, we create a HOME constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKbQPEucWjDV",
        "outputId": "b7aea859-27c9-4096-fc79-5d60558ddb17"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f3yporxZMl6"
      },
      "source": [
        "## Image Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "918C9laRZQj7"
      },
      "source": [
        "NOTE: To use Autodistill all you need to have is a set of images that you want to automatically annotate and use for target model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woGPiVXYZK6l"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2q7nt-OZq5y"
      },
      "source": [
        "NOTE: If you want to build YOLOv8 on your data, make sure to upload it into images directory that we just created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCziloKQZ_wd"
      },
      "source": [
        "### Download Raw Videos (optional)\n",
        "\n",
        "NOTE: In this tutorial, we will start with a directory containing video files and I will show you how to turn it into a ready to use collection of images. If you are working with your images, you can skip this part.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci1GjgUMacK0",
        "outputId": "bd280b87-9567-4b4d-ba22-c59046f0a666"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/videos\n",
        "%cd {HOME}/videos\n",
        "\n",
        "# download zip file conatining videos\n",
        "!wget https://media.roboflow.com/milk.zip\n",
        "\n",
        "# unzip videos\n",
        "!unzip milk.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFCXVr4GeSCB"
      },
      "source": [
        "### Convert videos into images (optional)\n",
        "\n",
        "Note: Let's convert videos into images. By default, the code belore saves every 10th frame from each video. You can change this by manipulating the value of the `FRAME_STRIDE` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxubIvL7e3ER"
      },
      "outputs": [],
      "source": [
        "VIDEO_DIR_PATH = f\"{HOME}/videos\"\n",
        "IMAGE_DIR_PATH = f\"{HOME}/images\"\n",
        "FRAME_STRIDE = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wROdWe2KfCfL"
      },
      "source": [
        "NOTE: notice that we put two of our videos aside so that we can use them at the end of the notebook to evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "604928724869475fbf07d694f55f1642",
            "f4704fbb7f6547819cdf59690398fc8b",
            "fdabb0e7376b458e97aceafe138df1f5",
            "0c26671527804d9c9081faf89398eee9",
            "f48fe9c35f5b4f66b74372eb390426ed",
            "85c52be623024f7aaca00ec642234886",
            "d873c6bd87a047bd82d0dc0f4d3cfe14",
            "cac667589c7e4d959cec167ff56e5fd1",
            "be17ed06a1b4468e8c69b00042c55c36",
            "8d171632576d4b7eb723a90eccbcbdae",
            "e84b5f832ed24872af3b8cd1d6673cb3"
          ]
        },
        "id": "-GSmrG6FfTRi",
        "outputId": "3152ba99-6b76-49ec-fac7-52eb92bac0c9"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "video_paths = sv.list_files_with_extensions(\n",
        "    directory = VIDEO_DIR_PATH,\n",
        "    extensions = [\"mov\", \"mp4\"]\n",
        ")\n",
        "\n",
        "TEST_VIDEO_PATHS, TRAIN_VIDEO_PATHS = video_paths[:2], video_paths[2:]\n",
        "\n",
        "for video_path in tqdm(TRAIN_VIDEO_PATHS):\n",
        "  video_name = video_path.stem\n",
        "  image_name_pattern = video_name + \"-{:05d}.png\"\n",
        "  with sv.ImageSink(target_dir_path=IMAGE_DIR_PATH, image_name_pattern=image_name_pattern) as sink:\n",
        "    for image in sv.get_video_frames_generator(source_path=str(video_path), stride = FRAME_STRIDE):\n",
        "      sink.save_image(image=image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiHkeV4pgceE"
      },
      "source": [
        "### Display image sample\n",
        "\n",
        "NOTE: Before we start building a model with autodistill, let's make sure we have everything we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iuXa2HrgwQf",
        "outputId": "fcf2951b-a7a1-46e9-e6be-1d943dc6fa28"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "image_paths = sv.list_files_with_extensions(\n",
        "    directory = IMAGE_DIR_PATH,\n",
        "    extensions = [\"png\", \"jpg\", \"jpg\"]\n",
        ")\n",
        "print('image count:', len(image_paths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTyD-jAqg92c"
      },
      "source": [
        "NOTE: We can also plot sample of our image dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK00eUtHhCTD"
      },
      "outputs": [],
      "source": [
        "IMAGE_DIR_PATH = f\"{HOME}/images\"\n",
        "SAMPLE_SIZE = 16\n",
        "SAMPLE_GRID_SIZE = (4,4)\n",
        "SAMPLE_PLOT_SIZE = (16,16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "DSkUsF74hYaz",
        "outputId": "d9628ff4-f6ab-41e7-eb15-437feeec5b4f"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import supervision as sv\n",
        "\n",
        "titles = [\n",
        "    image_path.stem\n",
        "    for image_path in image_paths[:SAMPLE_SIZE]\n",
        "]\n",
        "\n",
        "images = [\n",
        "    cv2.imread(str(image_path))\n",
        "    for image_path\n",
        "    in image_paths[:SAMPLE_SIZE]\n",
        "]\n",
        "sv.plot_images_grid(images=images, titles=titles,grid_size=SAMPLE_GRID_SIZE, size=SAMPLE_PLOT_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKSKNK1fijb7"
      },
      "source": [
        "## Autolabel Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrx8l79Ui8eb"
      },
      "source": [
        "### Ontology\n",
        "An ontology defines how your Base Model is prompted, what your Dataset will describe and what your target model will predict. A simple ontology is the CaptionOntology which prompts a Base Model with text Captions and maps them to Class names. Other Ontologies may for instance use a CLIP vector or example images instead of a text caption."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7VWtRmGkxx7",
        "outputId": "5344ea55-5c7b-41fb-ae52-2d6dd9675a73"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYCOb5sOkdW6"
      },
      "outputs": [],
      "source": [
        "from autodistill.detection import CaptionOntology\n",
        "\n",
        "ontology = CaptionOntology({\n",
        "    \"milk bottle\": \"bottle\",\n",
        "    \"blue cap\": \"cap\"\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcadAgzqkqVu"
      },
      "source": [
        "### Initiate base model and autolabel\n",
        "\n",
        "Base Model: A Base model is a large foundation model that knows a lot about a lot. Base models are often multimodal and can perform many tasks. They are large, slow and expensive. Examples of Base models are GroundedSAM and GPT-4's upcoming multimodal variant. We use a Base Model(along with unlabeled input data and an Ontology) to create a Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyEHRUIqmE8o"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR_PATH = f\"{HOME}/dataset\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMMy9MfemJwr"
      },
      "source": [
        "NOTE: Base Models are slow, Make yourself a coffee, autolabeling may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "9wvzhzzqmQqZ",
        "outputId": "89135a8d-a2f2-4cca-c4d0-f8b13fdd2081"
      },
      "outputs": [],
      "source": [
        "from autodistill_grounded_sam import GroundedSAM\n",
        "\n",
        "base_model = GroundedSAM(ontology=ontology)\n",
        "dataset = base_model.label(\n",
        "    input_folder = IMAGE_DIR_PATH,\n",
        "    extension = \".png\",\n",
        "    output_folder = DATASET_DIR_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMPdzmrkmno7"
      },
      "source": [
        "### Display dataset sample\n",
        "Dataset: A dataset is a set of auto-labeled data that can be used to train a Target model. It is the output generated by a Base Model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyEJ0VRsoVuy"
      },
      "outputs": [],
      "source": [
        "ANNOTATIONS_DIRECTORY_PATH = f\"{HOME}/dataset/train/labels\"\n",
        "IMAGES_DIRECTORY_PATH = f\"{HOME}/dataset/train/images\"\n",
        "DATA_YAML_PATH = f\"{HOME}/dataset/data.yaml\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZqZHEeionW6"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "dataset = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path = IMAGES_DIRECTORY_PATH,\n",
        "    annotations_directory_path = ANNOTATIONS_DIRECTORY_PATH,\n",
        "    data_yaml_path = DATA_YAML_PATH\n",
        ")\n",
        "\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPo-ZByStQJg"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "image_names = list(dataset.images.keys())[:SAMPLE_SIZE]\n",
        "\n",
        "mask_annotator = sv.MaskAnnotator()\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "\n",
        "images = []\n",
        "for image_name in image_names:\n",
        "  image = dataset.images[image_name]\n",
        "  annotations = dataset.annotations[image_name]\n",
        "  labels = [\n",
        "      dataset.classes[class_id]\n",
        "      for class_id in annotations.class_id\n",
        "  ]\n",
        "  annotates_image = mask_annotator.annotate(\n",
        "      scene = image.copy(),\n",
        "      detections = annotations\n",
        "  )\n",
        "  annotates_image = box_annotator.annotate(\n",
        "      scene = annotates_image,\n",
        "      detections = annotations,\n",
        "      labels = labels\n",
        "  )\n",
        "  images.append(annotates_image)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images = images,\n",
        "    titles = image_names,\n",
        "    grid_size = SAMPLE_GRID_SIZE,\n",
        "    size = SAMPLE_PLOT_SIZE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train target model - YOLOv8\n",
        "\n",
        "Target Model: A target model is a supervised model that consumes a Dataset and outputs a distilled model that is ready for deployment. Target models are usually small, fast and fine-tuned to perform a specific task very well (but they don't generalize well beyond the information describes in their Dataset). Example of Target Models are YOLOv8 and DETR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "from autodistill_yolov8 import YOLOv8\n",
        "\n",
        "target_model = YOLOv8(\"yolov8n.pt\")\n",
        "target_model.train(DATA_YAML_PATH, epochs=50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate target model\n",
        "\n",
        "NOTE: As with the regular YOLOv8 training, we can now take a look at artifacts stored in runs directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "Image(filename = f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "Image(filename = f'{HOME}/runs/detect/train/results.png', width = 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "from IPython.display import Image\n",
        "Image(filename = f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Inference on a Video\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INPUT_VIDEO_PATH = TEST_VIDEO_PATHS[0]\n",
        "OUTPUT_VIDEO_PATH = f\"{HOME}/output.mp4\"\n",
        "TRAINED_MODEL_PATH = f\"{HOME}/runs/detect/train/weights/best.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!yolo predict model={TRAINED_MODEL_PATH} source={INPUT_VIDEO_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c26671527804d9c9081faf89398eee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d171632576d4b7eb723a90eccbcbdae",
            "placeholder": "​",
            "style": "IPY_MODEL_e84b5f832ed24872af3b8cd1d6673cb3",
            "value": " 6/6 [02:30&lt;00:00, 22.92s/it]"
          }
        },
        "604928724869475fbf07d694f55f1642": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4704fbb7f6547819cdf59690398fc8b",
              "IPY_MODEL_fdabb0e7376b458e97aceafe138df1f5",
              "IPY_MODEL_0c26671527804d9c9081faf89398eee9"
            ],
            "layout": "IPY_MODEL_f48fe9c35f5b4f66b74372eb390426ed"
          }
        },
        "85c52be623024f7aaca00ec642234886": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d171632576d4b7eb723a90eccbcbdae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be17ed06a1b4468e8c69b00042c55c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cac667589c7e4d959cec167ff56e5fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d873c6bd87a047bd82d0dc0f4d3cfe14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e84b5f832ed24872af3b8cd1d6673cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4704fbb7f6547819cdf59690398fc8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85c52be623024f7aaca00ec642234886",
            "placeholder": "​",
            "style": "IPY_MODEL_d873c6bd87a047bd82d0dc0f4d3cfe14",
            "value": "100%"
          }
        },
        "f48fe9c35f5b4f66b74372eb390426ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdabb0e7376b458e97aceafe138df1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cac667589c7e4d959cec167ff56e5fd1",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be17ed06a1b4468e8c69b00042c55c36",
            "value": 6
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
