{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-track-the-objects-in-zone-using-ultralytics-yolo.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  \n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the Object tracking in zones using Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EM2nwU4jshF"
      },
      "source": [
        "# TrackZone using Ultralytics YOLO11\n",
        "\n",
        "This notebook serves as a starting point for [tracking objects in zones](https://docs.ultralytics.com/guides/trackzone/) in videos or live streams using the YOLO11 model.\n",
        "\n",
        "### What is TrackZone?\n",
        "\n",
        "TrackZone specializes in monitoring objects within designated areas of a frame instead of the whole frame. Built on [Ultralytics YOLO11](https://github.com/ultralytics/ultralytics/), it integrates object detection and tracking specifically within zones for videos and live camera feeds. YOLO11's advanced algorithms and [deep learning](https://www.ultralytics.com/glossary/deep-learning-dl) technologies make it a perfect choice for real-time use cases, offering precise and efficient object tracking in applications like crowd monitoring and surveillance.\n",
        "\n",
        "### Advantages of Object Tracking in Zones (TrackZone)\n",
        "\n",
        "- **Targeted Analysis:** Tracking objects within specific zones allows for more focused insights, enabling precise monitoring and analysis of areas of interest, such as entry points or restricted zones.\n",
        "- **Improved Efficiency:** By narrowing the tracking scope to defined zones, TrackZone reduces computational overhead, ensuring faster processing and optimal performance.\n",
        "- **Enhanced Security:** Zonal tracking improves surveillance by monitoring critical areas, aiding in the early detection of unusual activity or security breaches.\n",
        "- **Scalable Solutions:** The ability to focus on specific zones makes TrackZone adaptable to various scenarios, from retail spaces to industrial settings, ensuring seamless integration and scalability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "### Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.173 üöÄ Python-3.13.5 torch-2.7.1 CPU (Apple M4 Pro)\n",
            "Setup complete ‚úÖ (14 CPUs, 48.0 GB RAM, 689.1/926.4 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "import cv2\n",
        "from ultralytics.utils.downloads import safe_download\n",
        "from ultralytics import solutions\n",
        "\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8go3HNgN0WU"
      },
      "source": [
        "### Read the Video File\n",
        "\n",
        "- You can either read the video file directly or stream the content from an RTSP (Real-Time Streaming Protocol) source, allowing for flexible video input depending on your needs.\n",
        "- We will also set up the video writer to handle the output video writing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QUgMYUvlNLvy"
      },
      "outputs": [],
      "source": [
        "# safe_download(\"https://github.com/ultralytics/notebooks/releases/download/v0.0.0/solutions-ci-demo.mp4\")\n",
        "cap = cv2.VideoCapture(\"solutions-ci-demo.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH,\n",
        "                                       cv2.CAP_PROP_FRAME_HEIGHT,\n",
        "                                       cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Video writer\n",
        "video_writer = cv2.VideoWriter(\"trackzone.avi\",\n",
        "                               cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "                               fps, (w, h))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wJlBXORXNsj"
      },
      "source": [
        "### Define Region Coordinates\n",
        "\n",
        "Here, we set the coordinates for specific regions to ensure accurate object tracking and analysis within the video or stream. This helps monitor and track objects effectively in different areas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bVCrrForXRgS"
      },
      "outputs": [],
      "source": [
        "# Define region points\n",
        "# region_points = [(20, 400), (1080, 400)]  # For line tracking\n",
        "region_points = [(0, 0), (w, 0), (w, h), (0, h)]  # For rectangle region tracking\n",
        "# region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360), (20, 400)]  # For polygon region tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt3soEHzXe8c"
      },
      "source": [
        "### Initialize the TrackZone Class\n",
        "\n",
        "- Next, let's initialize the `TrackZone` class to track objects in each frame of the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Va24DpUZXTh3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics Solutions: ‚úÖ {'source': None, 'model': 'yolo11m.pt', 'classes': [0, 2], 'show_conf': True, 'show_labels': True, 'region': [(0, 0), (640, 0), (640, 360), (0, 360)], 'colormap': 21, 'show_in': True, 'show_out': True, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'figsize': (12.8, 7.2), 'blur_ratio': 0.5, 'vision_point': (20, 20), 'crop_dir': 'cropped-detections', 'json_file': None, 'line_width': 2, 'records': 5, 'fps': 30.0, 'max_hist': 5, 'meter_per_pixel': 0.05, 'max_speed': 120, 'show': True, 'iou': 0.7, 'conf': 0.25, 'device': None, 'max_det': 300, 'half': False, 'tracker': 'botsort.yaml', 'verbose': True, 'data': 'images'}\n"
          ]
        }
      ],
      "source": [
        " # Init TrackZone (Object Tracking in Zones, not complete frame)\n",
        "trackzone = solutions.TrackZone(\n",
        "    show=True,  # Display the output\n",
        "    region=region_points,  # Pass region points\n",
        "    model=\"yolo11m.pt\",  # You can use any model that Ultralytics support, i.e. YOLOv9, YOLOv10\n",
        "    line_width=2,  # Adjust the line width for bounding boxes and text display\n",
        "    classes=[0, 2],  # If you want to track specific classes i.e. person and car with COCO pretrained model.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ewYRFFqXvtj"
      },
      "source": [
        "### Process Video Frames\n",
        "\n",
        "In this step, we will process each frame of the video to detect and analyze objects. This allows for real-time tracking, based on the visual data in the frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVf1pyRtXijz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 360x640 18.6ms\n",
            "Speed: 673.1ms track, 18.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "1: 360x640 19.5ms\n",
            "Speed: 72.4ms track, 19.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "2: 360x640 13.7ms\n",
            "Speed: 72.8ms track, 13.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "3: 360x640 12.5ms\n",
            "Speed: 69.1ms track, 12.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "4: 360x640 1.7ms\n",
            "Speed: 70.2ms track, 1.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "5: 360x640 12.5ms\n",
            "Speed: 70.9ms track, 12.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "6: 360x640 14.0ms\n",
            "Speed: 70.2ms track, 14.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "7: 360x640 11.8ms\n",
            "Speed: 69.7ms track, 11.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "8: 360x640 12.0ms\n",
            "Speed: 69.6ms track, 12.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "9: 360x640 12.6ms\n",
            "Speed: 70.2ms track, 12.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "10: 360x640 12.4ms\n",
            "Speed: 70.8ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "11: 360x640 12.4ms\n",
            "Speed: 70.7ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "12: 360x640 12.4ms\n",
            "Speed: 70.1ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "13: 360x640 12.4ms\n",
            "Speed: 71.3ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "14: 360x640 12.8ms\n",
            "Speed: 70.6ms track, 12.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "15: 360x640 12.8ms\n",
            "Speed: 71.6ms track, 12.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "16: 360x640 13.4ms\n",
            "Speed: 71.9ms track, 13.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "17: 360x640 12.6ms\n",
            "Speed: 70.8ms track, 12.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "18: 360x640 12.4ms\n",
            "Speed: 70.0ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "19: 360x640 12.3ms\n",
            "Speed: 71.1ms track, 12.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "20: 360x640 12.4ms\n",
            "Speed: 72.2ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "21: 360x640 12.5ms\n",
            "Speed: 71.5ms track, 12.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "22: 360x640 12.4ms\n",
            "Speed: 72.0ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "23: 360x640 12.3ms\n",
            "Speed: 70.0ms track, 12.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "24: 360x640 12.4ms\n",
            "Speed: 72.5ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "25: 360x640 12.4ms\n",
            "Speed: 70.9ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "26: 360x640 12.4ms\n",
            "Speed: 72.8ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "27: 360x640 12.4ms\n",
            "Speed: 69.7ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "28: 360x640 12.4ms\n",
            "Speed: 72.7ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "29: 360x640 11.7ms\n",
            "Speed: 68.7ms track, 11.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "30: 360x640 12.5ms\n",
            "Speed: 68.6ms track, 12.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "31: 360x640 11.7ms\n",
            "Speed: 68.2ms track, 11.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "32: 360x640 12.5ms\n",
            "Speed: 68.6ms track, 12.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "33: 360x640 12.5ms\n",
            "Speed: 68.5ms track, 12.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "34: 360x640 12.5ms\n",
            "Speed: 68.7ms track, 12.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "35: 360x640 12.4ms\n",
            "Speed: 67.6ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "36: 360x640 12.4ms\n",
            "Speed: 68.3ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "37: 360x640 12.3ms\n",
            "Speed: 67.8ms track, 12.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "38: 360x640 11.8ms\n",
            "Speed: 68.5ms track, 11.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "39: 360x640 12.4ms\n",
            "Speed: 68.1ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "40: 360x640 12.4ms\n",
            "Speed: 67.2ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "41: 360x640 12.4ms\n",
            "Speed: 66.4ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "42: 360x640 12.4ms\n",
            "Speed: 69.2ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "43: 360x640 12.4ms\n",
            "Speed: 67.6ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "44: 360x640 12.3ms\n",
            "Speed: 66.7ms track, 12.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "45: 360x640 12.5ms\n",
            "Speed: 68.6ms track, 12.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "46: 360x640 12.4ms\n",
            "Speed: 68.3ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "47: 360x640 12.5ms\n",
            "Speed: 68.6ms track, 12.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "48: 360x640 12.4ms\n",
            "Speed: 68.0ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "49: 360x640 12.4ms\n",
            "Speed: 69.4ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "50: 360x640 12.4ms\n",
            "Speed: 67.7ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "51: 360x640 12.4ms\n",
            "Speed: 69.4ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "52: 360x640 12.4ms\n",
            "Speed: 69.6ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "53: 360x640 12.4ms\n",
            "Speed: 67.9ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "54: 360x640 12.6ms\n",
            "Speed: 69.2ms track, 12.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "55: 360x640 12.3ms\n",
            "Speed: 72.0ms track, 12.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "56: 360x640 12.4ms\n",
            "Speed: 75.5ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "57: 360x640 12.4ms\n",
            "Speed: 71.4ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "58: 360x640 12.3ms\n",
            "Speed: 70.6ms track, 12.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "59: 360x640 12.3ms\n",
            "Speed: 70.0ms track, 12.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "60: 360x640 12.3ms\n",
            "Speed: 71.2ms track, 12.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "61: 360x640 12.4ms\n",
            "Speed: 72.3ms track, 12.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "Video frame is empty or video processing has been successfully completed.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "    results = trackzone(im0)  # track the objects\n",
        "    video_writer.write(results.plot_im)   # write the video frames\n",
        "\n",
        "cap.release()   # Release the capture\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWskbLSKH2S5"
      },
      "source": [
        "![Plants Tracking in Field Using Ultralytics YOLO11](https://github.com/ultralytics/docs/releases/download/0/plants-tracking-in-zone-using-ultralytics-yolo11.avif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBUa5kZyZ2k"
      },
      "source": [
        "Crafted with üíô by [Ultralytics](https://ultralytics.com/)  \n",
        "\n",
        "üåü Explore and star the [Ultralytics Notebooks](https://github.com/ultralytics/notebooks/) to supercharge your AI journey! üöÄ"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ven2_cv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
