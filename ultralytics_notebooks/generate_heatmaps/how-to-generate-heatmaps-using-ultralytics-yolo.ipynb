{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN1cAxdvd61e"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
    "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
    "\n",
    "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
    "\n",
    "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
    "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-generate-heatmaps-using-ultralytics-yolo.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "  \n",
    "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
    "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
    "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
    "  \n",
    "  Welcome to the Heatmaps generation using Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64B195mdjxQd"
   },
   "source": [
    "# Generate Heatmaps using Ultralytics YOLO11\n",
    "\n",
    "This notebook serves as a starting point for generating the [heatmaps](https://docs.ultralytics.com/guides/heatmaps/) in videos or live streams using the YOLO11 model.\n",
    "\n",
    "### What is Heatmap?\n",
    "\n",
    "- A heatmap generated with [Ultralytics YOLO11](https://github.com/ultralytics/ultralytics/) transforms complex data into a vibrant, color-coded matrix. This visual tool employs a spectrum of colors to represent varying data values, where warmer hues indicate higher intensities and cooler tones signify lower values. Heatmaps excel in visualizing intricate data patterns, correlations, and anomalies, offering an accessible and engaging approach to data interpretation across diverse domains.\n",
    "\n",
    "### Why Choose Heatmaps for Data Analysis?\n",
    "\n",
    "- **Intuitive Data Distribution Visualization:** Heatmaps simplify the comprehension of data concentration and distribution, converting complex datasets into easy-to-understand visual formats.\n",
    "- **Efficient Pattern Detection:** By visualizing data in heatmap format, it becomes easier to spot trends, clusters, and outliers, facilitating quicker analysis and insights.\n",
    "- **Enhanced Spatial Analysis and Decision-Making:** Heatmaps are instrumental in illustrating spatial relationships, aiding in decision-making processes in sectors such as business intelligence, environmental studies, and urban planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o68Sg1oOeZm2"
   },
   "source": [
    "### Setup\n",
    "\n",
    "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
    "\n",
    "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dSwz_uOReMI",
    "outputId": "99866c77-e210-41e1-d581-8508371ce634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.173 üöÄ Python-3.13.5 torch-2.7.1 CPU (Apple M4 Pro)\n",
      "Setup complete ‚úÖ (14 CPUs, 48.0 GB RAM, 688.5/926.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import ultralytics\n",
    "from ultralytics import solutions\n",
    "from ultralytics.utils.downloads import safe_download\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpKaC03TZDlr"
   },
   "source": [
    "### Read the Video File\n",
    "\n",
    "You can either read the video file directly or stream the content from an RTSP (Real-Time Streaming Protocol) source, allowing for flexible video input depending on your needs. We will also set up the video writer to handle the output video writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2daZuXgaZDFH"
   },
   "outputs": [],
   "source": [
    "# safe_download(\"https://github.com/ultralytics/notebooks/releases/download/v0.0.0/solutions-ci-demo.mp4\")\n",
    "cap = cv2.VideoCapture(\"solutions-ci-demo.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"heatmap.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IlONOqdZKjz"
   },
   "source": [
    "### Define Region Coordinates (Optional)\n",
    "\n",
    "`Heatmap` solution doesn't require region coordinates by default, but If you want to count the objects in parallel during generation of heatmaps, you can pass the region coordinates for line counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t1sTggW6ZhTD"
   },
   "outputs": [],
   "source": [
    "# Define region points\n",
    "# region_points = [(20, 400), (1080, 400)]  # For line counting\n",
    "# region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]  # For rectangle region counting\n",
    "region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360), (20, 400)]  # For polygon region counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQSj3p4XZlj7"
   },
   "source": [
    "### Initialize the Heatmap Class\n",
    "\n",
    "Next, we will initialize the Heatmap class to track objects in each video frame and highlight the areas with the highest concentration of activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SpcXqN3DZ5rc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics Solutions: ‚úÖ {'source': None, 'model': 'yolo11l.pt', 'classes': [0, 2], 'show_conf': True, 'show_labels': True, 'region': [(20, 400), (1080, 400), (1080, 360), (20, 360), (20, 400)], 'colormap': 12, 'show_in': True, 'show_out': True, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'figsize': (12.8, 7.2), 'blur_ratio': 0.5, 'vision_point': (20, 20), 'crop_dir': 'cropped-detections', 'json_file': None, 'line_width': 2, 'records': 5, 'fps': 30.0, 'max_hist': 5, 'meter_per_pixel': 0.05, 'max_speed': 120, 'show': True, 'iou': 0.7, 'conf': 0.25, 'device': None, 'max_det': 300, 'half': False, 'tracker': 'botsort.yaml', 'verbose': True, 'data': 'images'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt to 'yolo11l.pt': 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49.0M/49.0M [00:02<00:00, 19.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Init heatmap\n",
    "heatmap = solutions.Heatmap(\n",
    "    show=True,  # Display the output\n",
    "    model=\"yolo11l.pt\",  # Path to the YOLO11 model file\n",
    "    colormap=cv2.COLORMAP_PARULA,  # Colormap of heatmap\n",
    "    region=region_points,  # If you want to do object counting with heatmaps, you can pass region_points\n",
    "    classes=[0, 2],  # If you want to generate heatmap for specific classes i.e person and car.\n",
    "    # show_in=True,  # Display in counts\n",
    "    # show_out=True,  # Display out counts\n",
    "    # line_width=2,  # Adjust the line width for bounding boxes and text display\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7VkxQ2aeg7k"
   },
   "source": [
    "### Process Video Frames\n",
    "\n",
    "In this step, we will analyze each video frame for object detection and tracking. We also generate heatmaps to highlight areas with the highest object concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cx-u59HQdu2o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 360x640 35.2ms\n",
      "Speed: 715.4ms track, 35.2ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "1: 360x640 9.3ms\n",
      "Speed: 92.6ms track, 9.3ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "2: 360x640 15.2ms\n",
      "Speed: 91.6ms track, 15.2ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "3: 360x640 14.1ms\n",
      "Speed: 92.6ms track, 14.1ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "4: 360x640 14.1ms\n",
      "Speed: 94.2ms track, 14.1ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "5: 360x640 14.3ms\n",
      "Speed: 103.2ms track, 14.3ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "6: 360x640 15.1ms\n",
      "Speed: 95.8ms track, 15.1ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "7: 360x640 13.8ms\n",
      "Speed: 94.0ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "8: 360x640 14.2ms\n",
      "Speed: 94.6ms track, 14.2ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "9: 360x640 15.9ms\n",
      "Speed: 101.1ms track, 15.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "10: 360x640 14.1ms\n",
      "Speed: 95.5ms track, 14.1ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "11: 360x640 13.9ms\n",
      "Speed: 94.3ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "12: 360x640 14.1ms\n",
      "Speed: 95.4ms track, 14.1ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "13: 360x640 13.6ms\n",
      "Speed: 93.3ms track, 13.6ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "14: 360x640 13.9ms\n",
      "Speed: 97.0ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "15: 360x640 13.8ms\n",
      "Speed: 96.9ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "16: 360x640 13.7ms\n",
      "Speed: 95.9ms track, 13.7ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "17: 360x640 13.7ms\n",
      "Speed: 94.8ms track, 13.7ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "18: 360x640 13.8ms\n",
      "Speed: 96.3ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "19: 360x640 13.5ms\n",
      "Speed: 95.8ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "20: 360x640 13.5ms\n",
      "Speed: 96.5ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "21: 360x640 13.5ms\n",
      "Speed: 94.8ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "22: 360x640 13.6ms\n",
      "Speed: 91.4ms track, 13.6ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "23: 360x640 13.7ms\n",
      "Speed: 93.9ms track, 13.7ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "24: 360x640 13.7ms\n",
      "Speed: 92.2ms track, 13.7ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "25: 360x640 13.8ms\n",
      "Speed: 92.6ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "26: 360x640 13.3ms\n",
      "Speed: 92.2ms track, 13.3ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "27: 360x640 13.9ms\n",
      "Speed: 92.4ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "28: 360x640 14.3ms\n",
      "Speed: 93.2ms track, 14.3ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "29: 360x640 12.8ms\n",
      "Speed: 95.3ms track, 12.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "30: 360x640 13.5ms\n",
      "Speed: 94.2ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "31: 360x640 13.7ms\n",
      "Speed: 93.2ms track, 13.7ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "32: 360x640 12.8ms\n",
      "Speed: 93.3ms track, 12.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "33: 360x640 13.9ms\n",
      "Speed: 95.5ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "34: 360x640 13.9ms\n",
      "Speed: 92.4ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "35: 360x640 13.8ms\n",
      "Speed: 93.0ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "36: 360x640 13.8ms\n",
      "Speed: 93.2ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "37: 360x640 13.6ms\n",
      "Speed: 89.6ms track, 13.6ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "38: 360x640 13.9ms\n",
      "Speed: 89.5ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "39: 360x640 12.8ms\n",
      "Speed: 90.9ms track, 12.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "40: 360x640 13.9ms\n",
      "Speed: 88.6ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "41: 360x640 13.6ms\n",
      "Speed: 90.5ms track, 13.6ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "42: 360x640 13.6ms\n",
      "Speed: 89.9ms track, 13.6ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "43: 360x640 13.7ms\n",
      "Speed: 90.2ms track, 13.7ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "44: 360x640 13.5ms\n",
      "Speed: 89.3ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "45: 360x640 13.5ms\n",
      "Speed: 88.3ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "46: 360x640 13.6ms\n",
      "Speed: 91.1ms track, 13.6ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "47: 360x640 13.8ms\n",
      "Speed: 88.4ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "48: 360x640 14.2ms\n",
      "Speed: 90.5ms track, 14.2ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "49: 360x640 13.6ms\n",
      "Speed: 90.6ms track, 13.6ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "50: 360x640 14.9ms\n",
      "Speed: 93.0ms track, 14.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "51: 360x640 13.9ms\n",
      "Speed: 92.0ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "52: 360x640 16.2ms\n",
      "Speed: 92.2ms track, 16.2ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "53: 360x640 13.9ms\n",
      "Speed: 92.6ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "54: 360x640 14.0ms\n",
      "Speed: 91.2ms track, 14.0ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "55: 360x640 13.6ms\n",
      "Speed: 89.5ms track, 13.6ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "56: 360x640 13.5ms\n",
      "Speed: 91.1ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "57: 360x640 13.9ms\n",
      "Speed: 87.4ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "58: 360x640 14.3ms\n",
      "Speed: 92.3ms track, 14.3ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "59: 360x640 14.1ms\n",
      "Speed: 92.8ms track, 14.1ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "60: 360x640 14.2ms\n",
      "Speed: 94.4ms track, 14.2ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "61: 360x640 13.8ms\n",
      "Speed: 93.4ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
      "\n",
      "Video frame is empty or video processing has been successfully completed.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    results = heatmap(im0)  # generate heatmap the objects\n",
    "    video_writer.write(results.plot_im)  # write the video frame\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()  # release the video_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRALUInRkadi"
   },
   "source": [
    "![Ultralytics YOLO11 Retail Heatmap](https://github.com/ultralytics/docs/releases/download/0/ultralytics-yolov8-retail-heatmap.avif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwBUa5kZyZ2k"
   },
   "source": [
    "Crafted with üíô by [Ultralytics](https://ultralytics.com/)  \n",
    "\n",
    "üåü Explore and star the [Ultralytics Notebooks](https://github.com/ultralytics/notebooks/) to supercharge your AI journey! üöÄ"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ven2_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
